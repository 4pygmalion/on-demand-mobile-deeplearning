{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import timeit\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append('/home/hoheon/packages/')\n",
    "\n",
    "from utils.keras import get_model_memory_usage\n",
    "from utils.numpy import to_onehot\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 32, 32, 3) (35000, 10)\n",
      "N classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "train, test = tf.keras.datasets.cifar10.load_data()\n",
    "tf.config.list_physical_devices()\n",
    "x_train, y_train = train[0], train[1]\n",
    "x_test, y_test = test[0], test[1]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3)\n",
    "\n",
    "y_train = to_onehot(y_train, 10).reshape(-1, 10)\n",
    "y_val = to_onehot(y_val, 10).reshape(-1, 10)\n",
    "y_test = to_onehot(y_test, 10).reshape(-1, 10)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(\"N classes: {}\".format(y_test.shape[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    sub_model = tf.keras.applications.VGG19(include_top=False, input_shape=(32, 32, 3), classes=10)\n",
    "    sub_model.trainable = False\n",
    "\n",
    "    flat = tf.keras.layers.Flatten()(sub_model.layers[-1].output)\n",
    "    classify_ = tf.keras.layers.Dense(10, activation='softmax')(flat)\n",
    "    model = tf.keras.Model(inputs=sub_model.inputs, outputs=classify_)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    lr_decay = tf.keras.callbacks.ReduceLROnPlateau()\n",
    "    check_pt = tf.keras.callbacks.ModelCheckpoint('./cache/best_param.hdf5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    EPOCHS = 500\n",
    "    BATCH_SIZE = 300\n",
    "    CB = [lr_decay, check_pt]\n",
    "\n",
    "\n",
    "    history  = model.fit(x=x_train, \n",
    "                          y=y_train,\n",
    "                          epochs=EPOCHS,\n",
    "                          validation_data=(x_val,  y_val),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          callbacks=CB,\n",
    "                          verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_model = tf.keras.applications.VGG19(include_top=False, input_shape=(32, 32, 3), classes=10)\n",
    "sub_model.trainable = False\n",
    "\n",
    "flat = tf.keras.layers.Flatten()(sub_model.layers[-1].output)\n",
    "classify_ = tf.keras.layers.Dense(10, activation='softmax')(flat)\n",
    "model = tf.keras.Model(inputs=sub_model.inputs, outputs=classify_)\n",
    "\n",
    "\n",
    "model.load_weights('./cache/best_param.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.numpy import to_onehot\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "y_hat = model.predict(x_test)\n",
    "y_label = to_onehot(np.argmax(y_hat, axis=1), 10)\n",
    "\n",
    "\n",
    "cm = multilabel_confusion_matrix(y_test, y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_runtime(index, batch, model, repeat=150, return_size=False):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    index: int:\n",
    "        layer index\n",
    "    model: keras.model\n",
    "    repeate: int\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    runtime: [sec, sec, sec...] \n",
    "    dsize: /kbyte\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    front_model = tf.keras.Model(model.input, model.layers[index-1].output)\n",
    "    front_output = front_model(batch)\n",
    "    \n",
    "    runtimes = []\n",
    "    for _ in range(repeat):\n",
    "        start_time = timeit.default_timer()\n",
    "        model.layers[index](front_output)\n",
    "        end_time = timeit.default_timer()\n",
    "        \n",
    "        runtime = end_time - start_time\n",
    "        runtimes.append(runtime)\n",
    "    \n",
    "    if return_size == False:\n",
    "        return runtimes\n",
    "    else:\n",
    "        return_val = model.layers[index](front_output)\n",
    "        mem_size = return_val.numpy().nbytes / 1024\n",
    "        return runtimes, mem_size\n",
    "\n",
    "\n",
    "resource_consump = dict()\n",
    "\n",
    "for i in range(0, len(model.layers)):\n",
    "    runtimes, d_size = layer_runtime(i, x_train[0:1], model, repeat=50, return_size=True)\n",
    "    \n",
    "    l_name = model.layers[i].name\n",
    "    resource_consump[l_name] = {'runtime':runtimes, 'dsize':d_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "for layer_name in list(resource_consump.keys()):\n",
    "    _df = pd.DataFrame(resource_consump[layer_name]['runtime'])\n",
    "    _df['layer_name'] = layer_name\n",
    "    df.append(_df)\n",
    "    \n",
    "runtimes = pd.concat(df)\n",
    "runtimes.columns = ['runtime', 'layer_name']\n",
    "runtimes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for layer_name in list(resource_consump.keys()):\n",
    "    _dsize = resource_consump[layer_name]['dsize']\n",
    "    df.append([layer_name, _dsize])\n",
    "    \n",
    "d_size = pd.DataFrame(df)\n",
    "d_size.columns = ['layer_name', 'dsize']\n",
    "d_size.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10 ,10))\n",
    "sns.boxplot(y='runtime', x='layer_name', data=runtimes, orient='v')\n",
    "\n",
    "\n",
    "plt.ylim(-0.0001, 0.001)\n",
    "plt.xticks(rotation=80)\n",
    "\n",
    "ax2 = plt.twinx()\n",
    "sns.lineplot(x='layer_name', y='dsize', data=d_size, ax=ax2, markers='*', color='red', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 32803.8281 - accuracy: 0.3815\n",
      "Epoch 2/10\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 29497.9297 - accuracy: 0.4665\n",
      "Epoch 3/10\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 30720.2090 - accuracy: 0.4920\n",
      "Epoch 4/10\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 28989.8340 - accuracy: 0.5187\n",
      "Epoch 5/10\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 28091.7773 - accuracy: 0.5396\n",
      "Epoch 6/10\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 27951.6934 - accuracy: 0.5511\n",
      "Epoch 7/10\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 26218.1602 - accuracy: 0.5693\n",
      "Epoch 8/10\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 25467.9277 - accuracy: 0.5832\n",
      "Epoch 9/10\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 24908.2109 - accuracy: 0.5868\n",
      "Epoch 10/10\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 25091.9043 - accuracy: 0.5967\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                655370    \n",
      "=================================================================\n",
      "Total params: 657,162\n",
      "Trainable params: 655,370\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class VGG19EX(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, exit_point):\n",
    "        super(VGG19EX, self).__init__()\n",
    "        \n",
    "        # Instance variables with as global param in class\n",
    "        self.EXITPT = exit_point\n",
    "        \n",
    "        # subclass\n",
    "        self.base_model = tf.keras.applications.VGG19(include_top=False, input_shape=(32, 32, 3), classes=10)\n",
    "        self.base_model.trainable = False\n",
    "        self.graph = self.build_graph_by_sub()\n",
    "        \n",
    "        n_layers= len(self.base_model.layers)\n",
    "        if self.EXITPT not in range(0, n_layers):\n",
    "            raise ValueError('exit_point must be in range(0, 22)')\n",
    "            \n",
    "    \n",
    "    def summary(self):\n",
    "        stringlist = []\n",
    "        self.graph.summary(print_fn=lambda x: stringlist.append(x))\n",
    "        stringlist_summary = \"\\n\".join(stringlist)\n",
    "        print(stringlist_summary)\n",
    "        \n",
    "    def build_graph_by_sub(self):\n",
    "        sub_graph = tf.keras.models.Model(self.base_model.input, \n",
    "                                          self.base_model.layers[self.EXITPT].output)\n",
    "        \n",
    "        _flatten = tf.keras.layers.Flatten()(sub_graph.output)\n",
    "        _fc = tf.keras.layers.Dense(10, activation='softmax')(_flatten)\n",
    "        trimed_graph = tf.keras.Model(inputs=sub_graph.input, outputs=_fc)\n",
    "        return trimed_graph\n",
    "    \n",
    "    def call(self, x):  \n",
    "        x = self.graph(x)\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        _ =  self.build_graph_by_sub()\n",
    "        print (_.summary())\n",
    "    \n",
    "    \n",
    "vgg = VGG19EX(exit_point=1)\n",
    "vgg.compile(optimizer=tf.keras.optimizers.Adam(0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "vgg.fit(x_train, y_train, epochs=10)\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "WARNING:tensorflow:From /home/hoheon/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "The model of exit point 1 was learn\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "The model of exit point 2 was learn\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "The model of exit point 3 was learn\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "The model of exit point 4 was learn\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "The model of exit point 5 was learn\n",
      "The model of exit point 6 was learn\n",
      "The model of exit point 7 was learn\n",
      "The model of exit point 8 was learn\n",
      "The model of exit point 9 was learn\n",
      "The model of exit point 10 was learn\n",
      "The model of exit point 11 was learn\n",
      "The model of exit point 12 was learn\n",
      "The model of exit point 13 was learn\n",
      "The model of exit point 14 was learn\n",
      "The model of exit point 15 was learn\n",
      "The model of exit point 16 was learn\n",
      "The model of exit point 17 was learn\n",
      "The model of exit point 18 was learn\n",
      "The model of exit point 19 was learn\n",
      "The model of exit point 20 was learn\n",
      "The model of exit point 21 was learn\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "history_master = {}\n",
    "\n",
    "for i in range (1, 22):\n",
    "    with strategy.scope():\n",
    "\n",
    "        vgg = VGG19EX(exit_point=i)\n",
    "        vgg.compile(optimizer=tf.keras.optimizers.Adam(0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        lr_decay = tf.keras.callbacks.ReduceLROnPlateau()\n",
    "        check_pt = tf.keras.callbacks.ModelCheckpoint('./weights/best_param_exit{}.hdf5'.format(i),\n",
    "                                                      monitor='val_loss', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "        EPOCHS = 500\n",
    "        BATCH_SIZE = 300\n",
    "        CB = [lr_decay, check_pt]\n",
    "\n",
    "\n",
    "        history  = vgg.fit(x=x_train, \n",
    "                          y=y_train,\n",
    "                          epochs=EPOCHS,\n",
    "                          validation_data=(x_val,  y_val),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          callbacks=CB,\n",
    "                          verbose=False)\n",
    "        \n",
    "        history_master['exit{}'.format(i)] = history\n",
    "    \n",
    "    print(\"The model of exit point {} was learn\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_memory_usage(1, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
